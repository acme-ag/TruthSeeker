{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b3027f35-4069-44bb-a956-29a576501394",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1fa9b551-d00a-4f26-9ced-8a57a9799fb4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "96b3b986-91fc-41e1-8431-fd2adfb63c53",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pd.set_option('display.max_colwidth', None)\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "695b1672-6e50-41fc-b24b-3ad77eff1005",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('../data/Original_data/Features_For_Traditional_ML_Techniques.csv')\n",
    "# df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bbf8cadc-dac0-4216-9334-24776a6a5052",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 134198 entries, 0 to 134197\n",
      "Data columns (total 64 columns):\n",
      " #   Column                  Non-Null Count   Dtype  \n",
      "---  ------                  --------------   -----  \n",
      " 0   Unnamed: 0              134198 non-null  int64  \n",
      " 1   majority_target         134198 non-null  bool   \n",
      " 2   statement               134198 non-null  object \n",
      " 3   BinaryNumTarget         134198 non-null  float64\n",
      " 4   tweet                   134198 non-null  object \n",
      " 5   followers_count         134198 non-null  float64\n",
      " 6   friends_count           134198 non-null  float64\n",
      " 7   favourites_count        134198 non-null  float64\n",
      " 8   statuses_count          134198 non-null  float64\n",
      " 9   listed_count            134198 non-null  float64\n",
      " 10  following               134198 non-null  float64\n",
      " 11  embeddings              134198 non-null  object \n",
      " 12  BotScore                134198 non-null  float64\n",
      " 13  BotScoreBinary          134198 non-null  float64\n",
      " 14  cred                    134198 non-null  float64\n",
      " 15  normalize_influence     134198 non-null  float64\n",
      " 16  mentions                134198 non-null  float64\n",
      " 17  quotes                  134198 non-null  float64\n",
      " 18  replies                 134198 non-null  float64\n",
      " 19  retweets                134198 non-null  float64\n",
      " 20  favourites              134198 non-null  float64\n",
      " 21  hashtags                134198 non-null  float64\n",
      " 22  URLs                    134198 non-null  float64\n",
      " 23  unique_count            134198 non-null  int64  \n",
      " 24  total_count             134198 non-null  int64  \n",
      " 25  ORG_percentage          134198 non-null  float64\n",
      " 26  NORP_percentage         134198 non-null  float64\n",
      " 27  GPE_percentage          134198 non-null  float64\n",
      " 28  PERSON_percentage       134198 non-null  float64\n",
      " 29  MONEY_percentage        134198 non-null  float64\n",
      " 30  DATE_percentage         134198 non-null  float64\n",
      " 31  CARDINAL_percentage     134198 non-null  float64\n",
      " 32  PERCENT_percentage      134198 non-null  float64\n",
      " 33  ORDINAL_percentage      134198 non-null  float64\n",
      " 34  FAC_percentage          134198 non-null  float64\n",
      " 35  LAW_percentage          134198 non-null  float64\n",
      " 36  PRODUCT_percentage      134198 non-null  float64\n",
      " 37  EVENT_percentage        134198 non-null  float64\n",
      " 38  TIME_percentage         134198 non-null  float64\n",
      " 39  LOC_percentage          134198 non-null  float64\n",
      " 40  WORK_OF_ART_percentage  134198 non-null  float64\n",
      " 41  QUANTITY_percentage     134198 non-null  float64\n",
      " 42  LANGUAGE_percentage     134198 non-null  float64\n",
      " 43  Word count              134198 non-null  int64  \n",
      " 44  Max word length         134198 non-null  int64  \n",
      " 45  Min word length         134198 non-null  int64  \n",
      " 46  Average word length     134198 non-null  float64\n",
      " 47  present_verbs           134198 non-null  int64  \n",
      " 48  past_verbs              134198 non-null  int64  \n",
      " 49  adjectives              134198 non-null  int64  \n",
      " 50  adverbs                 134198 non-null  int64  \n",
      " 51  adpositions             134198 non-null  int64  \n",
      " 52  pronouns                134198 non-null  int64  \n",
      " 53  TOs                     134198 non-null  int64  \n",
      " 54  determiners             134198 non-null  int64  \n",
      " 55  conjunctions            134198 non-null  int64  \n",
      " 56  dots                    134198 non-null  int64  \n",
      " 57  exclamation             134198 non-null  int64  \n",
      " 58  questions               134198 non-null  int64  \n",
      " 59  ampersand               134198 non-null  int64  \n",
      " 60  capitals                134198 non-null  int64  \n",
      " 61  digits                  134198 non-null  int64  \n",
      " 62  long_word_freq          134198 non-null  int64  \n",
      " 63  short_word_freq         134198 non-null  int64  \n",
      "dtypes: bool(1), float64(37), int64(23), object(3)\n",
      "memory usage: 64.6+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cb54bb4-23ed-4f49-aa14-e2d7185535d3",
   "metadata": {},
   "source": [
    "# Check the data validity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e64f0de8-3f9c-40f9-b081-a4de05fdaa6c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# df.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "477c9fdb-0337-4e5c-aaef-ce7807756aaa",
   "metadata": {},
   "source": [
    "0-th item tweet text:\n",
    "\n",
    "\"@POTUS Biden Blunders - 6 Month Update\n",
    "\n",
    "Inflation, Delta mismanagement, COVID for kids, Abandoning Americans in Afghanistan, Arming the Taliban, S. Border crisis, Breaking job growth, Abuse of power (Many Exec Orders, $3.5T through Reconciliation, Eviction Moratorium)...what did I miss?\"\n",
    "\n",
    "It says there're 6 'total_count', 42 'word count', 1 URL, 33% ORG_percentage that do not match the text content. 0 DATE, ORDINAL or CARDINAL percentage -- 6 Month must fall in one of the categories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b966a4ca-4558-42b5-8031-e8a8fcd98340",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Random datapoint\n",
    "# df.iloc[10520:10521]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52054f93-128a-4efe-ae22-e61d896ea333",
   "metadata": {},
   "source": [
    "It says: 1 URL, 0 total_count (?), 0 PERSON, 0 LOC (location), 0 CORDINAL, 0 PERCENT, 46 word count, Max word length 14, Min word lenght 1, 3 dots, 0 digits.\n",
    "\n",
    "In fact: 0 URLs, 38 total_count, word_count  probably should be 34 or 35, 1 location 3 CORDINAL and 1 PERCENT mentions, Max words is 9, Min words is 2, 15 digits, 2 dots."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "27fa3784-cbca-4752-a399-d3d9db35faa4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# df.iloc[80520:80521]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6509edea-3bc8-4b24-abb7-14e16589a72e",
   "metadata": {},
   "source": [
    "It says there's 1 URL, total_count 1 (that's total number of words), 0 MONEY entity, 0 CARDINAL, 0 TIME, 36 word count, Max word length 14, 0 exclamations, 0 digits, 8 capitals, 0 ampersand, 5 dots.\n",
    "\n",
    "In fact 0 URL, 54 total_count, 1 Money entity, 2 Cardinal, 1 Percent,1 Time, ~45 word count, the longest word is 'employees' that has 9 characters, several exclamations, 15 capital letters, 2 ampersands, 2 dots (if we count delimiter)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3fd1985e-90f7-4e0d-adac-c28a5cf0eb0a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Min word length'].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "244cefbd-53d3-4e07-a552-e6f7dbd82808",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: >"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAkIAAAGgCAYAAABGwwgUAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8fJSN1AAAACXBIWXMAAA9hAAAPYQGoP6dpAAA40UlEQVR4nO3df1RU953/8RfCMAKLU5CFcSwm5ByXaKBpFltFs1VXAbMi25Pd2pZkoluX2NVIKJgfxqaLtkJr/LULmzRxPTEnaOnZY8ym6rJgmmo5ICpKK2q1PTWiKYiN4+CvDBO43z+y3G9H/O0wVu/zcc6c0/nc973zuW8yyaufO3cmzDAMQwAAABY06E5PAAAA4E4hCAEAAMsiCAEAAMsiCAEAAMsiCAEAAMsiCAEAAMsiCAEAAMsiCAEAAMsiCAEAAMsiCAEAAMu66SC0c+dOzZgxQy6XS2FhYXr33XevWjt37lyFhYVpzZo1AeM+n08LFixQQkKCYmJilJeXp5MnTwbUeDweud1uORwOORwOud1unT17NqCmra1NM2bMUExMjBISElRYWKju7u6AmgMHDmjixImKiorS8OHDtXTpUvGrIgAAQJIibnaHCxcu6OGHH9Y//dM/6R/+4R+uWvfuu++qqalJLper37aioiL97Gc/U3V1tYYOHaqSkhLl5uaqublZ4eHhkqT8/HydPHlSNTU1kqSnn35abrdbP/vZzyRJPT09mj59uv7yL/9S9fX1+vjjjzVr1iwZhqGKigpJUldXl7KysjR58mTt2bNHR48e1ezZsxUTE6OSkpIbOt/e3l794Q9/UGxsrMLCwm6qVwAA4M4wDEPnzp2Ty+XSoEHXWPcxboMkY/Pmzf3GT548aQwfPtxobW017rvvPmP16tXmtrNnzxo2m82orq42xz766CNj0KBBRk1NjWEYhnHo0CFDkrFr1y6zprGx0ZBk/OY3vzEMwzC2bdtmDBo0yPjoo4/Mmp/85CeG3W43vF6vYRiG8eqrrxoOh8P45JNPzJry8nLD5XIZvb29N3SOJ06cMCTx4MGDBw8ePO7Cx4kTJ6753/mbXhG6nt7eXrndbj333HN66KGH+m1vbm6W3+9Xdna2OeZyuZSWlqaGhgbl5OSosbFRDodDY8eONWvGjRsnh8OhhoYGpaamqrGxUWlpaQErTjk5OfL5fGpubtbkyZPV2NioiRMnym63B9QsWrRIH374oVJSUvrNz+fzyefzmc+N/7uMduzYMcXGxt5ec/6E3+/XBx98oMmTJ8tmswXtuAhEn0OHXocGfQ4N+hwaA9nnc+fOKSUl5br/7Q56EPrRj36kiIgIFRYWXnF7R0eHIiMjFRcXFzCelJSkjo4OsyYxMbHfvomJiQE1SUlJAdvj4uIUGRkZUHP//ff3e52+bVcKQuXl5VqyZEm/8cbGRkVHR1/xnG5VdHS0mpqagnpM9EefQ4dehwZ9Dg36HBoD1eeLFy9K0nU/1hLUINTc3Kx/+7d/0759+2768zSGYQTsc6X9g1HTt8JztfktWrRIxcXF5vOuri4lJycrOztbQ4YMucGzuT6/36+6ujplZWXx/zYGEH0OHXodGvQ5NOhzaAxkn7u6um6oLqhB6Je//KU6Ozs1YsQIc6ynp0clJSVas2aNPvzwQzmdTnV3d8vj8QSsCnV2dmr8+PGSJKfTqVOnTvU7/unTp80VHafT2S9Bejwe+f3+gJq+1aE/fR1J/VaT+tjt9oBLaX1sNtuAvBkG6rgIRJ9Dh16HBn0ODfocGgPR5xs9XlC/R8jtduvXv/61WlpazIfL5dJzzz2n//3f/5UkZWRkyGazqa6uztyvvb1dra2tZhDKzMyU1+vV7t27zZqmpiZ5vd6AmtbWVrW3t5s1tbW1stvtysjIMGt27twZcEt9bW2tXC5Xv0tmAADAem56Rej8+fP63e9+Zz4/duyYWlpaFB8frxEjRmjo0KEB9TabTU6nU6mpqZIkh8OhOXPmqKSkREOHDlV8fLwWLlyo9PR0TZ06VZI0atQoTZs2TQUFBXr99dclfXb7fG5urnmc7OxsjR49Wm63W6+88orOnDmjhQsXqqCgwLyElZ+fryVLlmj27Nl66aWX9Nvf/lZlZWX63ve+x63wAADg5oPQ3r17NXnyZPN53+dpZs2apfXr19/QMVavXq2IiAjNnDlTly5d0pQpU7R+/XrzO4QkacOGDSosLDTvLsvLy1NlZaW5PTw8XFu3btW8efM0YcIERUVFKT8/XytWrDBrHA6H6urqNH/+fI0ZM0ZxcXEqLi4O+AwQAACwrpsOQpMmTbqpb2b+8MMP+40NHjxYFRUV5hcfXkl8fLyqqqqueewRI0Zoy5Yt16xJT0/Xzp07b2iuAADAWvitMQAAYFkEIQAAYFkEIQAAYFkEIQAAYFkEIQAAYFkEIQAAYFkEIQAAYFkEIQAAYFlB/dFV3Ly00v+Vr+fWfu7jwx9OD/JsAACwFlaEAACAZRGEAACAZRGEAACAZRGEAACAZRGEAACAZRGEAACAZRGEAACAZRGEAACAZRGEAACAZRGEAACAZRGEAACAZRGEAACAZRGEAACAZRGEAACAZRGEAACAZRGEAACAZRGEAACAZRGEAACAZRGEAACAZRGEAACAZRGEAACAZRGEAACAZRGEAACAZRGEAACAZRGEAACAZRGEAACAZRGEAACAZRGEAACAZRGEAACAZRGEAACAZRGEAACAZRGEAACAZd10ENq5c6dmzJghl8ulsLAwvfvuu+Y2v9+vF154Qenp6YqJiZHL5dJTTz2lP/zhDwHH8Pl8WrBggRISEhQTE6O8vDydPHkyoMbj8cjtdsvhcMjhcMjtduvs2bMBNW1tbZoxY4ZiYmKUkJCgwsJCdXd3B9QcOHBAEydOVFRUlIYPH66lS5fKMIybPW0AAHAPuukgdOHCBT388MOqrKzst+3ixYvat2+fXn75Ze3bt0/vvPOOjh49qry8vIC6oqIibd68WdXV1aqvr9f58+eVm5urnp4esyY/P18tLS2qqalRTU2NWlpa5Ha7ze09PT2aPn26Lly4oPr6elVXV2vTpk0qKSkxa7q6upSVlSWXy6U9e/aooqJCK1as0KpVq272tAEAwD0o4mZ3eOyxx/TYY49dcZvD4VBdXV3AWEVFhb785S+rra1NI0aMkNfr1bp16/T2229r6tSpkqSqqiolJydr+/btysnJ0eHDh1VTU6Ndu3Zp7NixkqS1a9cqMzNTR44cUWpqqmpra3Xo0CGdOHFCLpdLkrRy5UrNnj1by5Yt05AhQ7RhwwZ98sknWr9+vex2u9LS0nT06FGtWrVKxcXFCgsLu9nTBwAA95AB/4yQ1+tVWFiYPve5z0mSmpub5ff7lZ2dbda4XC6lpaWpoaFBktTY2CiHw2GGIEkaN26cHA5HQE1aWpoZgiQpJydHPp9Pzc3NZs3EiRNlt9sDav7whz/oww8/HKhTBgAAd4mbXhG6GZ988olefPFF5efna8iQIZKkjo4ORUZGKi4uLqA2KSlJHR0dZk1iYmK/4yUmJgbUJCUlBWyPi4tTZGRkQM3999/f73X6tqWkpPR7DZ/PJ5/PZz7v6uqS9Nnnn/x+/w2f+/X0Hcs+6NY/rxTM+dyr+npErwYevQ4N+hwa9Dk0BrLPN3rMAQtCfr9f3/jGN9Tb26tXX331uvWGYQRcqrrSZatg1PR9UPpql8XKy8u1ZMmSfuO1tbWKjo6+zlncvO+P6b3lfbdt2xbEmdzbLr9ki4FDr0ODPocGfQ6NgejzxYsXb6huQIKQ3+/XzJkzdezYMf385z83V4Mkyel0qru7Wx6PJ2BVqLOzU+PHjzdrTp061e+4p0+fNld0nE6nmpqaArZ7PB75/f6Amr7VoT99HUn9VpP6LFq0SMXFxebzrq4uJScnKzs7O+A8bpff71ddXZ1e3jtIvt5b+6xSa2lO0OZzr+rrc1ZWlmw2252ezj2NXocGfQ4N+hwaA9nnvis61xP0INQXgn7729/qgw8+0NChQwO2Z2RkyGazqa6uTjNnzpQktbe3q7W1VcuXL5ckZWZmyuv1avfu3fryl78sSWpqapLX6zXDUmZmppYtW6b29nYNGzZM0merNna7XRkZGWbNSy+9pO7ubkVGRpo1Lper3yWzPna7PeAzRX1sNtuAvBl8vWHy9dxaEOLNeeMG6u+H/uh1aNDn0KDPoTEQfb7R4930h6XPnz+vlpYWtbS0SJKOHTumlpYWtbW16dNPP9U//uM/au/evdqwYYN6enrU0dGhjo4O8/t9HA6H5syZo5KSEr3//vvav3+/nnzySaWnp5t3kY0aNUrTpk1TQUGBdu3apV27dqmgoEC5ublKTU2VJGVnZ2v06NFyu93av3+/3n//fS1cuFAFBQXmyk1+fr7sdrtmz56t1tZWbd68WWVlZdwxBgAAJN3CitDevXs1efJk83nfZaRZs2aptLRU7733niTpi1/8YsB+H3zwgSZNmiRJWr16tSIiIjRz5kxdunRJU6ZM0fr16xUeHm7Wb9iwQYWFhebdZXl5eQHfXRQeHq6tW7dq3rx5mjBhgqKiopSfn68VK1aYNX2388+fP19jxoxRXFyciouLAy59AQAA67rpIDRp0qRrfjPzjXxr8+DBg1VRUaGKioqr1sTHx6uqquqaxxkxYoS2bNlyzZr09HTt3LnzunMCAADWw2+NAQAAyyIIAQAAyyIIAQAAyyIIAQAAyyIIAQAAyyIIAQAAyyIIAQAAyyIIAQAAyyIIAQAAyyIIAQAAyyIIAQAAyyIIAQAAyyIIAQAAyyIIAQAAyyIIAQAAyyIIAQAAyyIIAQAAyyIIAQAAyyIIAQAAyyIIAQAAyyIIAQAAyyIIAQAAyyIIAQAAyyIIAQAAyyIIAQAAyyIIAQAAyyIIAQAAyyIIAQAAyyIIAQAAyyIIAQAAyyIIAQAAyyIIAQAAyyIIAQAAyyIIAQAAyyIIAQAAyyIIAQAAyyIIAQAAyyIIAQAAyyIIAQAAyyIIAQAAyyIIAQAAyyIIAQAAy7rpILRz507NmDFDLpdLYWFhevfddwO2G4ah0tJSuVwuRUVFadKkSTp48GBAjc/n04IFC5SQkKCYmBjl5eXp5MmTATUej0dut1sOh0MOh0Nut1tnz54NqGlra9OMGTMUExOjhIQEFRYWqru7O6DmwIEDmjhxoqKiojR8+HAtXbpUhmHc7GkDAIB70E0HoQsXLujhhx9WZWXlFbcvX75cq1atUmVlpfbs2SOn06msrCydO3fOrCkqKtLmzZtVXV2t+vp6nT9/Xrm5uerp6TFr8vPz1dLSopqaGtXU1KilpUVut9vc3tPTo+nTp+vChQuqr69XdXW1Nm3apJKSErOmq6tLWVlZcrlc2rNnjyoqKrRixQqtWrXqZk8bAADcgyJudofHHntMjz322BW3GYahNWvWaPHixXr88cclSW+99ZaSkpK0ceNGzZ07V16vV+vWrdPbb7+tqVOnSpKqqqqUnJys7du3KycnR4cPH1ZNTY127dqlsWPHSpLWrl2rzMxMHTlyRKmpqaqtrdWhQ4d04sQJuVwuSdLKlSs1e/ZsLVu2TEOGDNGGDRv0ySefaP369bLb7UpLS9PRo0e1atUqFRcXKyws7JaaBgAA7g03HYSu5dixY+ro6FB2drY5ZrfbNXHiRDU0NGju3Llqbm6W3+8PqHG5XEpLS1NDQ4NycnLU2Ngoh8NhhiBJGjdunBwOhxoaGpSamqrGxkalpaWZIUiScnJy5PP51NzcrMmTJ6uxsVETJ06U3W4PqFm0aJE+/PBDpaSk9DsHn88nn89nPu/q6pIk+f1++f3+4DTq/44nSfZBt36ZLpjzuVf19YheDTx6HRr0OTToc2gMZJ9v9JhBDUIdHR2SpKSkpIDxpKQkHT9+3KyJjIxUXFxcv5q+/Ts6OpSYmNjv+ImJiQE1l79OXFycIiMjA2ruv//+fq/Tt+1KQai8vFxLlizpN15bW6vo6Ogrn/ht+P6Y3lved9u2bUGcyb2trq7uTk/BMuh1aNDn0KDPoTEQfb548eIN1QU1CPW5/JKTYRjXvQx1ec2V6oNR0/dB6avNZ9GiRSouLjafd3V1KTk5WdnZ2RoyZMg1z+Fm+P1+1dXV6eW9g+TrvbVLdK2lOUGbz72qr89ZWVmy2Wx3ejr3NHodGvQ5NOhzaAxkn/uu6FxPUIOQ0+mU9Nlqy7Bhw8zxzs5OcyXG6XSqu7tbHo8nYFWos7NT48ePN2tOnTrV7/inT58OOE5TU1PAdo/HI7/fH1DTtzr0p68j9V+16mO32wMupfWx2WwD8mbw9YbJ13NrQYg3540bqL8f+qPXoUGfQ4M+h8ZA9PlGjxfU7xFKSUmR0+kMWOLq7u7Wjh07zJCTkZEhm80WUNPe3q7W1lazJjMzU16vV7t37zZrmpqa5PV6A2paW1vV3t5u1tTW1sputysjI8Os2blzZ8At9bW1tXK5XP0umQEAAOu56SB0/vx5tbS0qKWlRdJnH5BuaWlRW1ubwsLCVFRUpLKyMm3evFmtra2aPXu2oqOjlZ+fL0lyOByaM2eOSkpK9P7772v//v168sknlZ6ebt5FNmrUKE2bNk0FBQXatWuXdu3apYKCAuXm5io1NVWSlJ2drdGjR8vtdmv//v16//33tXDhQhUUFJiXsPLz82W32zV79my1trZq8+bNKisr444xAAAg6RYuje3du1eTJ082n/d9nmbWrFlav369nn/+eV26dEnz5s2Tx+PR2LFjVVtbq9jYWHOf1atXKyIiQjNnztSlS5c0ZcoUrV+/XuHh4WbNhg0bVFhYaN5dlpeXF/DdReHh4dq6davmzZunCRMmKCoqSvn5+VqxYoVZ43A4VFdXp/nz52vMmDGKi4tTcXFxwGeAAACAdd10EJo0adI1v5k5LCxMpaWlKi0tvWrN4MGDVVFRoYqKiqvWxMfHq6qq6ppzGTFihLZs2XLNmvT0dO3cufOaNQAAwJr4rTEAAGBZBCEAAGBZBCEAAGBZBCEAAGBZBCEAAGBZBCEAAGBZBCEAAGBZBCEAAGBZBCEAAGBZBCEAAGBZBCEAAGBZBCEAAGBZBCEAAGBZBCEAAGBZBCEAAGBZBCEAAGBZBCEAAGBZBCEAAGBZBCEAAGBZBCEAAGBZBCEAAGBZBCEAAGBZBCEAAGBZBCEAAGBZBCEAAGBZBCEAAGBZBCEAAGBZBCEAAGBZBCEAAGBZBCEAAGBZBCEAAGBZBCEAAGBZBCEAAGBZBCEAAGBZBCEAAGBZBCEAAGBZBCEAAGBZBCEAAGBZBCEAAGBZBCEAAGBZBCEAAGBZQQ9Cn376qb773e8qJSVFUVFReuCBB7R06VL19vaaNYZhqLS0VC6XS1FRUZo0aZIOHjwYcByfz6cFCxYoISFBMTExysvL08mTJwNqPB6P3G63HA6HHA6H3G63zp49G1DT1tamGTNmKCYmRgkJCSosLFR3d3ewTxsAANyFgh6EfvSjH+nHP/6xKisrdfjwYS1fvlyvvPKKKioqzJrly5dr1apVqqys1J49e+R0OpWVlaVz586ZNUVFRdq8ebOqq6tVX1+v8+fPKzc3Vz09PWZNfn6+WlpaVFNTo5qaGrW0tMjtdpvbe3p6NH36dF24cEH19fWqrq7Wpk2bVFJSEuzTBgAAd6GIYB+wsbFRf//3f6/p06dLku6//3795Cc/0d69eyV9thq0Zs0aLV68WI8//rgk6a233lJSUpI2btyouXPnyuv1at26dXr77bc1depUSVJVVZWSk5O1fft25eTk6PDhw6qpqdGuXbs0duxYSdLatWuVmZmpI0eOKDU1VbW1tTp06JBOnDghl8slSVq5cqVmz56tZcuWaciQIcE+fQAAcBcJehB69NFH9eMf/1hHjx7VX/3VX+lXv/qV6uvrtWbNGknSsWPH1NHRoezsbHMfu92uiRMnqqGhQXPnzlVzc7P8fn9AjcvlUlpamhoaGpSTk6PGxkY5HA4zBEnSuHHj5HA41NDQoNTUVDU2NiotLc0MQZKUk5Mjn8+n5uZmTZ48ud/8fT6ffD6f+byrq0uS5Pf75ff7g9anvmPZBxm3fQxcXV+P6NXAo9ehQZ9Dgz6HxkD2+UaPGfQg9MILL8jr9erBBx9UeHi4enp6tGzZMn3zm9+UJHV0dEiSkpKSAvZLSkrS8ePHzZrIyEjFxcX1q+nbv6OjQ4mJif1ePzExMaDm8teJi4tTZGSkWXO58vJyLVmypN94bW2toqOjr3v+N+v7Y3qvX3QV27ZtC+JM7m11dXV3egqWQa9Dgz6HBn0OjYHo88WLF2+oLuhB6Kc//amqqqq0ceNGPfTQQ2ppaVFRUZFcLpdmzZpl1oWFhQXsZxhGv7HLXV5zpfpbqflTixYtUnFxsfm8q6tLycnJys7ODuqlNL/fr7q6Or28d5B8vdc+76tpLc0J2nzuVX19zsrKks1mu9PTuafR69Cgz6FBn0NjIPvcd0XneoIehJ577jm9+OKL+sY3viFJSk9P1/Hjx1VeXq5Zs2bJ6XRK+my1ZtiwYeZ+nZ2d5uqN0+lUd3e3PB5PwKpQZ2enxo8fb9acOnWq3+ufPn064DhNTU0B2z0ej/x+f7+Voj52u112u73fuM1mG5A3g683TL6eWwtCvDlv3ED9/dAfvQ4N+hwa9Dk0BqLPN3q8oN81dvHiRQ0aFHjY8PBw8/b5lJQUOZ3OgGWw7u5u7dixwww5GRkZstlsATXt7e1qbW01azIzM+X1erV7926zpqmpSV6vN6CmtbVV7e3tZk1tba3sdrsyMjKCfOYAAOBuE/QVoRkzZmjZsmUaMWKEHnroIe3fv1+rVq3St771LUmfXaoqKipSWVmZRo4cqZEjR6qsrEzR0dHKz8+XJDkcDs2ZM0clJSUaOnSo4uPjtXDhQqWnp5t3kY0aNUrTpk1TQUGBXn/9dUnS008/rdzcXKWmpkqSsrOzNXr0aLndbr3yyis6c+aMFi5cqIKCAu4YAwAAwQ9CFRUVevnllzVv3jx1dnbK5XJp7ty5+t73vmfWPP/887p06ZLmzZsnj8ejsWPHqra2VrGxsWbN6tWrFRERoZkzZ+rSpUuaMmWK1q9fr/DwcLNmw4YNKiwsNO8uy8vLU2Vlpbk9PDxcW7du1bx58zRhwgRFRUUpPz9fK1asCPZpAwCAu1DQg1BsbKzWrFlj3i5/JWFhYSotLVVpaelVawYPHqyKioqAL2K8XHx8vKqqqq45nxEjRmjLli3XmzYAALAgfmsMAABYFkEIAABYFkEIAABYFkEIAABYFkEIAABYFkEIAABYFkEIAABYFkEIAABYFkEIAABYFkEIAABYFkEIAABYFkEIAABYFkEIAABYFkEIAABYFkEIAABYFkEIAABYFkEIAABYFkEIAABYFkEIAABYFkEIAABYFkEIAABYFkEIAABYFkEIAABYFkEIAABYFkEIAABYFkEIAABYFkEIAABYFkEIAABYFkEIAABYFkEIAABYFkEIAABYFkEIAABYFkEIAABYFkEIAABYFkEIAABYFkEIAABYFkEIAABYFkEIAABYFkEIAABYFkEIAABYFkEIAABYFkEIAABY1oAEoY8++khPPvmkhg4dqujoaH3xi19Uc3Ozud0wDJWWlsrlcikqKkqTJk3SwYMHA47h8/m0YMECJSQkKCYmRnl5eTp58mRAjcfjkdvtlsPhkMPhkNvt1tmzZwNq2traNGPGDMXExCghIUGFhYXq7u4eiNMGAAB3maAHIY/HowkTJshms+l//ud/dOjQIa1cuVKf+9znzJrly5dr1apVqqys1J49e+R0OpWVlaVz586ZNUVFRdq8ebOqq6tVX1+v8+fPKzc3Vz09PWZNfn6+WlpaVFNTo5qaGrW0tMjtdpvbe3p6NH36dF24cEH19fWqrq7Wpk2bVFJSEuzTBgAAd6GIYB/wRz/6kZKTk/Xmm2+aY/fff7/5vw3D0Jo1a7R48WI9/vjjkqS33npLSUlJ2rhxo+bOnSuv16t169bp7bff1tSpUyVJVVVVSk5O1vbt25WTk6PDhw+rpqZGu3bt0tixYyVJa9euVWZmpo4cOaLU1FTV1tbq0KFDOnHihFwulyRp5cqVmj17tpYtW6YhQ4YE+/QBAMBdJOhB6L333lNOTo6+9rWvaceOHRo+fLjmzZungoICSdKxY8fU0dGh7Oxscx+73a6JEyeqoaFBc+fOVXNzs/x+f0CNy+VSWlqaGhoalJOTo8bGRjkcDjMESdK4cePkcDjU0NCg1NRUNTY2Ki0tzQxBkpSTkyOfz6fm5mZNnjy53/x9Pp98Pp/5vKurS5Lk9/vl9/uD1qe+Y9kHGbd9DFxdX4/o1cCj16FBn0ODPofGQPb5Ro8Z9CD0+9//Xq+99pqKi4v10ksvaffu3SosLJTdbtdTTz2ljo4OSVJSUlLAfklJSTp+/LgkqaOjQ5GRkYqLi+tX07d/R0eHEhMT+71+YmJiQM3lrxMXF6fIyEiz5nLl5eVasmRJv/Ha2lpFR0ffSAtuyvfH9N7yvtu2bQviTO5tdXV1d3oKlkGvQ4M+hwZ9Do2B6PPFixdvqC7oQai3t1djxoxRWVmZJOmRRx7RwYMH9dprr+mpp54y68LCwgL2Mwyj39jlLq+5Uv2t1PypRYsWqbi42Hze1dWl5ORkZWdnB/VSmt/vV11dnV7eO0i+3muf99W0luYEbT73qr4+Z2VlyWaz3enp3NPodWjQ59Cgz6ExkH3uu6JzPUEPQsOGDdPo0aMDxkaNGqVNmzZJkpxOp6TPVmuGDRtm1nR2dpqrN06nU93d3fJ4PAGrQp2dnRo/frxZc+rUqX6vf/r06YDjNDU1BWz3eDzy+/39Vor62O122e32fuM2m21A3gy+3jD5em4tCPHmvHED9fdDf/Q6NOhzaNDn0BiIPt/o8YJ+19iECRN05MiRgLGjR4/qvvvukySlpKTI6XQGLIN1d3drx44dZsjJyMiQzWYLqGlvb1dra6tZk5mZKa/Xq927d5s1TU1N8nq9ATWtra1qb283a2pra2W325WRkRHkMwcAAHeboK8Ifec739H48eNVVlammTNnavfu3XrjjTf0xhtvSPrsUlVRUZHKyso0cuRIjRw5UmVlZYqOjlZ+fr4kyeFwaM6cOSopKdHQoUMVHx+vhQsXKj093byLbNSoUZo2bZoKCgr0+uuvS5Kefvpp5ebmKjU1VZKUnZ2t0aNHy+1265VXXtGZM2e0cOFCFRQUcMcYAAAIfhD60pe+pM2bN2vRokVaunSpUlJStGbNGj3xxBNmzfPPP69Lly5p3rx58ng8Gjt2rGpraxUbG2vWrF69WhEREZo5c6YuXbqkKVOmaP369QoPDzdrNmzYoMLCQvPusry8PFVWVprbw8PDtXXrVs2bN08TJkxQVFSU8vPztWLFimCfNgAAuAsFPQhJUm5urnJzc6+6PSwsTKWlpSotLb1qzeDBg1VRUaGKioqr1sTHx6uqquqacxkxYoS2bNly3TkDAADr4bfGAACAZRGEAACAZRGEAACAZRGEAACAZRGEAACAZRGEAACAZRGEAACAZRGEAACAZRGEAACAZRGEAACAZRGEAACAZRGEAACAZRGEAACAZRGEAACAZRGEAACAZRGEAACAZRGEAACAZRGEAACAZRGEAACAZRGEAACAZRGEAACAZRGEAACAZRGEAACAZRGEAACAZRGEAACAZRGEAACAZRGEAACAZRGEAACAZRGEAACAZRGEAACAZRGEAACAZRGEAACAZRGEAACAZRGEAACAZRGEAACAZRGEAACAZRGEAACAZRGEAACAZRGEAACAZRGEAACAZRGEAACAZQ14ECovL1dYWJiKiorMMcMwVFpaKpfLpaioKE2aNEkHDx4M2M/n82nBggVKSEhQTEyM8vLydPLkyYAaj8cjt9sth8Mhh8Mht9uts2fPBtS0tbVpxowZiomJUUJCggoLC9Xd3T1QpwsAAO4iAxqE9uzZozfeeENf+MIXAsaXL1+uVatWqbKyUnv27JHT6VRWVpbOnTtn1hQVFWnz5s2qrq5WfX29zp8/r9zcXPX09Jg1+fn5amlpUU1NjWpqatTS0iK3221u7+np0fTp03XhwgXV19erurpamzZtUklJyUCeNgAAuEsMWBA6f/68nnjiCa1du1ZxcXHmuGEYWrNmjRYvXqzHH39caWlpeuutt3Tx4kVt3LhRkuT1erVu3TqtXLlSU6dO1SOPPKKqqiodOHBA27dvlyQdPnxYNTU1+s///E9lZmYqMzNTa9eu1ZYtW3TkyBFJUm1trQ4dOqSqqio98sgjmjp1qlauXKm1a9eqq6troE4dAADcJSIG6sDz58/X9OnTNXXqVP3gBz8wx48dO6aOjg5lZ2ebY3a7XRMnTlRDQ4Pmzp2r5uZm+f3+gBqXy6W0tDQ1NDQoJydHjY2NcjgcGjt2rFkzbtw4ORwONTQ0KDU1VY2NjUpLS5PL5TJrcnJy5PP51NzcrMmTJ/ebt8/nk8/nM5/3BSa/3y+/3x+c5vzf8STJPsi47WPg6vp6RK8GHr0ODfocGvQ5NAayzzd6zAEJQtXV1dq3b5/27NnTb1tHR4ckKSkpKWA8KSlJx48fN2siIyMDVpL6avr27+joUGJiYr/jJyYmBtRc/jpxcXGKjIw0ay5XXl6uJUuW9Buvra1VdHT0Ffe5Hd8f03vL+27bti2IM7m31dXV3ekpWAa9Dg36HBr0OTQGos8XL168obqgB6ETJ07o2WefVW1trQYPHnzVurCwsIDnhmH0G7vc5TVXqr+Vmj+1aNEiFRcXm8+7urqUnJys7OxsDRky5Jrzuxl+v191dXV6ee8g+Xqvfd5X01qaE7T53Kv6+pyVlSWbzXanp3NPo9ehQZ9Dgz6HxkD2+UY/AhP0INTc3KzOzk5lZGSYYz09Pdq5c6cqKyvNz+90dHRo2LBhZk1nZ6e5euN0OtXd3S2PxxOwKtTZ2anx48ebNadOner3+qdPnw44TlNTU8B2j8cjv9/fb6Woj91ul91u7zdus9kG5M3g6w2Tr+fWghBvzhs3UH8/9EevQ4M+hwZ9Do2B6PONHi/oH5aeMmWKDhw4oJaWFvMxZswYPfHEE2ppadEDDzwgp9MZsAzW3d2tHTt2mCEnIyNDNpstoKa9vV2tra1mTWZmprxer3bv3m3WNDU1yev1BtS0traqvb3drKmtrZXdbg8IagAAwJqCviIUGxurtLS0gLGYmBgNHTrUHC8qKlJZWZlGjhypkSNHqqysTNHR0crPz5ckORwOzZkzRyUlJRo6dKji4+O1cOFCpaena+rUqZKkUaNGadq0aSooKNDrr78uSXr66aeVm5ur1NRUSVJ2drZGjx4tt9utV155RWfOnNHChQtVUFAQ1MtcAADg7jRgd41dy/PPP69Lly5p3rx58ng8Gjt2rGpraxUbG2vWrF69WhEREZo5c6YuXbqkKVOmaP369QoPDzdrNmzYoMLCQvPusry8PFVWVprbw8PDtXXrVs2bN08TJkxQVFSU8vPztWLFitCdLAAA+LMVkiD0i1/8IuB5WFiYSktLVVpaetV9Bg8erIqKClVUVFy1Jj4+XlVVVdd87REjRmjLli03M10AAGAR/NYYAACwLIIQAACwLIIQAACwLIIQAACwLIIQAACwLIIQAACwLIIQAACwLIIQAACwLIIQAACwLIIQAACwLIIQAACwLIIQAACwLIIQAACwLIIQAACwLIIQAACwLIIQAACwLIIQAACwLIIQAACwLIIQAACwLIIQAACwLIIQAACwLIIQAACwLIIQAACwLIIQAACwLIIQAACwLIIQAACwLIIQAACwLIIQAACwLIIQAACwLIIQAACwLIIQAACwLIIQAACwLIIQAACwLIIQAACwLIIQAACwLIIQAACwLIIQAACwLIIQAACwLIIQAACwLIIQAACwLIIQAACwLIIQAACwrKAHofLycn3pS19SbGysEhMT9dWvflVHjhwJqDEMQ6WlpXK5XIqKitKkSZN08ODBgBqfz6cFCxYoISFBMTExysvL08mTJwNqPB6P3G63HA6HHA6H3G63zp49G1DT1tamGTNmKCYmRgkJCSosLFR3d3ewTxsAANyFgh6EduzYofnz52vXrl2qq6vTp59+quzsbF24cMGsWb58uVatWqXKykrt2bNHTqdTWVlZOnfunFlTVFSkzZs3q7q6WvX19Tp//rxyc3PV09Nj1uTn56ulpUU1NTWqqalRS0uL3G63ub2np0fTp0/XhQsXVF9fr+rqam3atEklJSXBPm0AAHAXigj2AWtqagKev/nmm0pMTFRzc7O+8pWvyDAMrVmzRosXL9bjjz8uSXrrrbeUlJSkjRs3au7cufJ6vVq3bp3efvttTZ06VZJUVVWl5ORkbd++XTk5OTp8+LBqamq0a9cujR07VpK0du1aZWZm6siRI0pNTVVtba0OHTqkEydOyOVySZJWrlyp2bNna9myZRoyZEiwTx8AANxFgh6ELuf1eiVJ8fHxkqRjx46po6ND2dnZZo3dbtfEiRPV0NCguXPnqrm5WX6/P6DG5XIpLS1NDQ0NysnJUWNjoxwOhxmCJGncuHFyOBxqaGhQamqqGhsblZaWZoYgScrJyZHP51Nzc7MmT57cb74+n08+n8983tXVJUny+/3y+/1B6orMY9kHGbd9DFxdX4/o1cCj16FBn0ODPofGQPb5Ro85oEHIMAwVFxfr0UcfVVpamiSpo6NDkpSUlBRQm5SUpOPHj5s1kZGRiouL61fTt39HR4cSExP7vWZiYmJAzeWvExcXp8jISLPmcuXl5VqyZEm/8draWkVHR1/3nG/W98f03vK+27ZtC+JM7m11dXV3egqWQa9Dgz6HBn0OjYHo88WLF2+obkCD0DPPPKNf//rXqq+v77ctLCws4LlhGP3GLnd5zZXqb6XmTy1atEjFxcXm866uLiUnJys7Ozuol9L8fr/q6ur08t5B8vVe+7yvprU0J2jzuVf19TkrK0s2m+1OT+eeRq9Dgz6HBn0OjYHsc98VnesZsCC0YMECvffee9q5c6c+//nPm+NOp1PSZ6s1w4YNM8c7OzvN1Run06nu7m55PJ6AVaHOzk6NHz/erDl16lS/1z19+nTAcZqamgK2ezwe+f3+fitFfex2u+x2e79xm802IG8GX2+YfD23FoR4c964gfr7oT96HRr0OTToc2gMRJ9v9HhBv2vMMAw988wzeuedd/Tzn/9cKSkpAdtTUlLkdDoDlsG6u7u1Y8cOM+RkZGTIZrMF1LS3t6u1tdWsyczMlNfr1e7du82apqYmeb3egJrW1la1t7ebNbW1tbLb7crIyAj2qQMAgLtM0FeE5s+fr40bN+q///u/FRsba34Wx+FwKCoqSmFhYSoqKlJZWZlGjhypkSNHqqysTNHR0crPzzdr58yZo5KSEg0dOlTx8fFauHCh0tPTzbvIRo0apWnTpqmgoECvv/66JOnpp59Wbm6uUlNTJUnZ2dkaPXq03G63XnnlFZ05c0YLFy5UQUEBd4wBAIDgB6HXXntNkjRp0qSA8TfffFOzZ8+WJD3//PO6dOmS5s2bJ4/Ho7Fjx6q2tlaxsbFm/erVqxUREaGZM2fq0qVLmjJlitavX6/w8HCzZsOGDSosLDTvLsvLy1NlZaW5PTw8XFu3btW8efM0YcIERUVFKT8/XytWrAj2aQMAgLtQ0IOQYVz/dvCwsDCVlpaqtLT0qjWDBw9WRUWFKioqrloTHx+vqqqqa77WiBEjtGXLluvOCQAAWA+/NQYAACyLIAQAACyLIAQAACyLIAQAACyLIAQAACyLIAQAACyLIAQAACyLIAQAACyLIAQAACyLIAQAACyLIAQAACyLIAQAACyLIAQAACyLIAQAACyLIAQAACyLIAQAACyLIAQAACyLIAQAACyLIAQAACyLIAQAACyLIAQAACyLIAQAACyLIAQAACyLIAQAACyLIAQAACyLIAQAACyLIAQAACyLIAQAACyLIAQAACyLIAQAACyLIAQAACyLIAQAACyLIAQAACyLIAQAACyLIAQAACyLIAQAACyLIAQAACyLIAQAACyLIAQAACyLIAQAACyLIAQAACzLEkHo1VdfVUpKigYPHqyMjAz98pe/vNNTAgAAfwbu+SD005/+VEVFRVq8eLH279+vv/mbv9Fjjz2mtra2Oz01AABwh93zQWjVqlWaM2eO/vmf/1mjRo3SmjVrlJycrNdee+1OTw0AANxhEXd6AgOpu7tbzc3NevHFFwPGs7Oz1dDQcMV9fD6ffD6f+dzr9UqSzpw5I7/fH7S5+f1+Xbx4URH+QerpDbulY3z88cdBm8+9qq/PH3/8sWw2252ezj2NXocGfQ4N+hwaA9nnc+fOSZIMw7hm3T0dhP74xz+qp6dHSUlJAeNJSUnq6Oi44j7l5eVasmRJv/GUlJQBmePtSFh5p2cAAMCft3PnzsnhcFx1+z0dhPqEhQWuuBiG0W+sz6JFi1RcXGw+7+3t1ZkzZzR06NCr7nMrurq6lJycrBMnTmjIkCFBOy4C0efQodehQZ9Dgz6HxkD22TAMnTt3Ti6X65p193QQSkhIUHh4eL/Vn87Ozn6rRH3sdrvsdnvA2Oc+97mBmqKGDBnCmywE6HPo0OvQoM+hQZ9DY6D6fK2VoD739IelIyMjlZGRobq6uoDxuro6jR8//g7NCgAA/Lm4p1eEJKm4uFhut1tjxoxRZmam3njjDbW1tenb3/72nZ4aAAC4w+75IPT1r39dH3/8sZYuXar29nalpaVp27Ztuu++++7ovOx2u/71X/+132U4BBd9Dh16HRr0OTToc2j8OfQ5zLjefWUAAAD3qHv6M0IAAADXQhACAACWRRACAACWRRACAACWRRC6Q1599VWlpKRo8ODBysjI0C9/+cs7PaW7Rnl5ub70pS8pNjZWiYmJ+upXv6ojR44E1BiGodLSUrlcLkVFRWnSpEk6ePBgQI3P59OCBQuUkJCgmJgY5eXl6eTJk6E8lbtKeXm5wsLCVFRUZI7R5+D56KOP9OSTT2ro0KGKjo7WF7/4RTU3N5vb6fXt+/TTT/Xd735XKSkpioqK0gMPPKClS5eqt7fXrKHPN2/nzp2aMWOGXC6XwsLC9O677wZsD1ZPPR6P3G63HA6HHA6H3G63zp49e/snYCDkqqurDZvNZqxdu9Y4dOiQ8eyzzxoxMTHG8ePH7/TU7go5OTnGm2++abS2thotLS3G9OnTjREjRhjnz583a374wx8asbGxxqZNm4wDBw4YX//6141hw4YZXV1dZs23v/1tY/jw4UZdXZ2xb98+Y/LkycbDDz9sfPrpp3fitP6s7d6927j//vuNL3zhC8azzz5rjtPn4Dhz5oxx3333GbNnzzaampqMY8eOGdu3bzd+97vfmTX0+vb94Ac/MIYOHWps2bLFOHbsmPFf//Vfxl/8xV8Ya9asMWvo883btm2bsXjxYmPTpk2GJGPz5s0B24PV02nTphlpaWlGQ0OD0dDQYKSlpRm5ubm3PX+C0B3w5S9/2fj2t78dMPbggw8aL7744h2a0d2ts7PTkGTs2LHDMAzD6O3tNZxOp/HDH/7QrPnkk08Mh8Nh/PjHPzYMwzDOnj1r2Gw2o7q62qz56KOPjEGDBhk1NTWhPYE/c+fOnTNGjhxp1NXVGRMnTjSDEH0OnhdeeMF49NFHr7qdXgfH9OnTjW9961sBY48//rjx5JNPGoZBn4Ph8iAUrJ4eOnTIkGTs2rXLrGlsbDQkGb/5zW9ua85cGgux7u5uNTc3Kzs7O2A8OztbDQ0Nd2hWdzev1ytJio+PlyQdO3ZMHR0dAT222+2aOHGi2ePm5mb5/f6AGpfLpbS0NP4Ol5k/f76mT5+uqVOnBozT5+B57733NGbMGH3ta19TYmKiHnnkEa1du9bcTq+D49FHH9X777+vo0ePSpJ+9atfqb6+Xn/3d38niT4PhGD1tLGxUQ6HQ2PHjjVrxo0bJ4fDcdt9v+e/WfrPzR//+Ef19PT0+9HXpKSkfj8Oi+szDEPFxcV69NFHlZaWJklmH6/U4+PHj5s1kZGRiouL61fD3+H/q66u1r59+7Rnz55+2+hz8Pz+97/Xa6+9puLiYr300kvavXu3CgsLZbfb9dRTT9HrIHnhhRfk9Xr14IMPKjw8XD09PVq2bJm++c1vSuKf6YEQrJ52dHQoMTGx3/ETExNvu+8EoTskLCws4LlhGP3GcH3PPPOMfv3rX6u+vr7ftlvpMX+H/+/EiRN69tlnVVtbq8GDB1+1jj7fvt7eXo0ZM0ZlZWWSpEceeUQHDx7Ua6+9pqeeesqso9e356c//amqqqq0ceNGPfTQQ2ppaVFRUZFcLpdmzZpl1tHn4AtGT69UH4y+c2ksxBISEhQeHt4vwXZ2dvZLzLi2BQsW6L333tMHH3ygz3/+8+a40+mUpGv22Ol0qru7Wx6P56o1Vtfc3KzOzk5lZGQoIiJCERER2rFjh/793/9dERERZp/o8+0bNmyYRo8eHTA2atQotbW1SeKf6WB57rnn9OKLL+ob3/iG0tPT5Xa79Z3vfEfl5eWS6PNACFZPnU6nTp061e/4p0+fvu2+E4RCLDIyUhkZGaqrqwsYr6ur0/jx4+/QrO4uhmHomWee0TvvvKOf//znSklJCdiekpIip9MZ0OPu7m7t2LHD7HFGRoZsNltATXt7u1pbW/k7/J8pU6bowIEDamlpMR9jxozRE088oZaWFj3wwAP0OUgmTJjQ7ysgjh49av44NP9MB8fFixc1aFDgf/bCw8PN2+fpc/AFq6eZmZnyer3avXu3WdPU1CSv13v7fb+tj1rjlvTdPr9u3Trj0KFDRlFRkRETE2N8+OGHd3pqd4V/+Zd/MRwOh/GLX/zCaG9vNx8XL140a374wx8aDofDeOedd4wDBw4Y3/zmN694u+bnP/95Y/v27ca+ffuMv/3bv7X0LbA34k/vGjMM+hwsu3fvNiIiIoxly5YZv/3tb40NGzYY0dHRRlVVlVlDr2/frFmzjOHDh5u3z7/zzjtGQkKC8fzzz5s19PnmnTt3zti/f7+xf/9+Q5KxatUqY//+/eZXwgSrp9OmTTO+8IUvGI2NjUZjY6ORnp7O7fN3s//4j/8w7rvvPiMyMtL467/+a/PWb1yfpCs+3nzzTbOmt7fX+Nd//VfD6XQadrvd+MpXvmIcOHAg4DiXLl0ynnnmGSM+Pt6IiooycnNzjba2thCfzd3l8iBEn4PnZz/7mZGWlmbY7XbjwQcfNN54442A7fT69nV1dRnPPvusMWLECGPw4MHGAw88YCxevNjw+XxmDX2+eR988MEV/508a9YswzCC19OPP/7YeOKJJ4zY2FgjNjbWeOKJJwyPx3Pb8w8zDMO4vTUlAACAuxOfEQIAAJZFEAIAAJZFEAIAAJZFEAIAAJZFEAIAAJZFEAIAAJZFEAIAAJZFEAIAAJZFEAIAAJZFEAIAAJZFEAIAAJZFEAIAAJb1/wALIdPTkw04kAAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df['Min word length'].hist(bins=30)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "384cc316-26d4-4163-b7d5-dd80bad113ed",
   "metadata": {},
   "source": [
    "So it says there's a tweet where shortest word counts 1000 characters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0b3d74c0-59c2-4d03-9165-a2682e8ced96",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'@sultana_laraib Why this apologetic stance? Being neighbor, Pakistan does have interests in Afghanistan which ought to be defended and advocated. We lost 100,000 civilian lives at the hands of butcher Afghans and many losses worth billion of dollars which we cant forget.'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[df['Min word length'].max()]['tweet']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c01b046-22ad-457b-ad5c-6ece4985ca4e",
   "metadata": {},
   "source": [
    "Word says it's 42."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "143e72df-cd63-4be7-90f6-3387e53eaa21",
   "metadata": {},
   "source": [
    "Ok, long story short. It's not just about these particular datapoints. There are descrepancies across the dataset. I think (and inderectly research team member confirmed that) the team was focused on the NLP analysis, rather than on traditional ML techniques. That ML dataset is kinda bonus. Or maybe something went wrong during data processing. So, anyway, there are descrepancies. \n",
    "\n",
    "Unfortunately I was not able to get the correct version from the researchers. So I've come up to the decision to make the recalculations. First I need to count all countable things like quantity of dots, digits, ! and ? signs, number of characters, longest and shortest words and so on.\n",
    "\n",
    "Then I'll deal with spacy tags. That's a new package for me, so need to get a bit familliar with that."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8877206e-2fb6-40dc-8161-ecf3ee74f670",
   "metadata": {},
   "source": [
    "------------------\n",
    "\n",
    "But before that, we want to deal with one thing. Although the data types look relevant for the variables, it's unclear why for some of them data type is int64 or float64 â€“ is it that necessary?\n",
    "\n",
    "The min and max values across the dataset show that there are no extremly large or small numbers there. They can be accomodatetd into a dtypes of smalleer capacities. Like Int32, which is -2,147,483,648 to +2,147,483,647.\n",
    "\n",
    "We gonna drop \"Unnamed 0\", since it's a double for index, following, since it's empty. All other variables with dtype int64, except for 'followers_count' will be converted into int32.\n",
    "\n",
    "------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e9e4f646-524b-4c00-8d2e-3f76976646a5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>BinaryNumTarget</th>\n",
       "      <th>followers_count</th>\n",
       "      <th>friends_count</th>\n",
       "      <th>favourites_count</th>\n",
       "      <th>statuses_count</th>\n",
       "      <th>listed_count</th>\n",
       "      <th>following</th>\n",
       "      <th>BotScore</th>\n",
       "      <th>BotScoreBinary</th>\n",
       "      <th>cred</th>\n",
       "      <th>normalize_influence</th>\n",
       "      <th>mentions</th>\n",
       "      <th>quotes</th>\n",
       "      <th>replies</th>\n",
       "      <th>retweets</th>\n",
       "      <th>favourites</th>\n",
       "      <th>hashtags</th>\n",
       "      <th>URLs</th>\n",
       "      <th>unique_count</th>\n",
       "      <th>total_count</th>\n",
       "      <th>ORG_percentage</th>\n",
       "      <th>NORP_percentage</th>\n",
       "      <th>GPE_percentage</th>\n",
       "      <th>PERSON_percentage</th>\n",
       "      <th>MONEY_percentage</th>\n",
       "      <th>DATE_percentage</th>\n",
       "      <th>CARDINAL_percentage</th>\n",
       "      <th>PERCENT_percentage</th>\n",
       "      <th>ORDINAL_percentage</th>\n",
       "      <th>FAC_percentage</th>\n",
       "      <th>LAW_percentage</th>\n",
       "      <th>PRODUCT_percentage</th>\n",
       "      <th>EVENT_percentage</th>\n",
       "      <th>TIME_percentage</th>\n",
       "      <th>LOC_percentage</th>\n",
       "      <th>WORK_OF_ART_percentage</th>\n",
       "      <th>QUANTITY_percentage</th>\n",
       "      <th>LANGUAGE_percentage</th>\n",
       "      <th>Word count</th>\n",
       "      <th>Max word length</th>\n",
       "      <th>Min word length</th>\n",
       "      <th>Average word length</th>\n",
       "      <th>present_verbs</th>\n",
       "      <th>past_verbs</th>\n",
       "      <th>adjectives</th>\n",
       "      <th>adverbs</th>\n",
       "      <th>adpositions</th>\n",
       "      <th>pronouns</th>\n",
       "      <th>TOs</th>\n",
       "      <th>determiners</th>\n",
       "      <th>conjunctions</th>\n",
       "      <th>dots</th>\n",
       "      <th>exclamation</th>\n",
       "      <th>questions</th>\n",
       "      <th>ampersand</th>\n",
       "      <th>capitals</th>\n",
       "      <th>digits</th>\n",
       "      <th>long_word_freq</th>\n",
       "      <th>short_word_freq</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>134198.00000</td>\n",
       "      <td>134198.000000</td>\n",
       "      <td>1.341980e+05</td>\n",
       "      <td>134198.000000</td>\n",
       "      <td>1.341980e+05</td>\n",
       "      <td>1.341980e+05</td>\n",
       "      <td>134198.000000</td>\n",
       "      <td>134198.0</td>\n",
       "      <td>134198.000000</td>\n",
       "      <td>134198.000000</td>\n",
       "      <td>134198.000000</td>\n",
       "      <td>134198.000000</td>\n",
       "      <td>134198.000000</td>\n",
       "      <td>134198.000000</td>\n",
       "      <td>134198.000000</td>\n",
       "      <td>134198.000000</td>\n",
       "      <td>134198.000000</td>\n",
       "      <td>134198.000000</td>\n",
       "      <td>134198.000000</td>\n",
       "      <td>134198.000000</td>\n",
       "      <td>134198.000000</td>\n",
       "      <td>134198.000000</td>\n",
       "      <td>134198.000000</td>\n",
       "      <td>134198.000000</td>\n",
       "      <td>134198.000000</td>\n",
       "      <td>134198.000000</td>\n",
       "      <td>134198.000000</td>\n",
       "      <td>134198.000000</td>\n",
       "      <td>134198.000000</td>\n",
       "      <td>134198.000000</td>\n",
       "      <td>134198.000000</td>\n",
       "      <td>134198.000000</td>\n",
       "      <td>134198.000000</td>\n",
       "      <td>134198.000000</td>\n",
       "      <td>134198.000000</td>\n",
       "      <td>134198.000000</td>\n",
       "      <td>134198.000000</td>\n",
       "      <td>134198.000000</td>\n",
       "      <td>134198.000000</td>\n",
       "      <td>134198.000000</td>\n",
       "      <td>134198.000000</td>\n",
       "      <td>134198.000000</td>\n",
       "      <td>134198.000000</td>\n",
       "      <td>134198.000000</td>\n",
       "      <td>134198.00000</td>\n",
       "      <td>134198.000000</td>\n",
       "      <td>134198.000000</td>\n",
       "      <td>134198.000000</td>\n",
       "      <td>134198.00000</td>\n",
       "      <td>134198.000000</td>\n",
       "      <td>134198.000000</td>\n",
       "      <td>134198.000000</td>\n",
       "      <td>134198.000000</td>\n",
       "      <td>134198.000000</td>\n",
       "      <td>134198.000000</td>\n",
       "      <td>134198.000000</td>\n",
       "      <td>134198.000000</td>\n",
       "      <td>134198.000000</td>\n",
       "      <td>134198.000000</td>\n",
       "      <td>134198.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>67098.50000</td>\n",
       "      <td>0.513644</td>\n",
       "      <td>1.129308e+04</td>\n",
       "      <td>1893.454455</td>\n",
       "      <td>3.298123e+04</td>\n",
       "      <td>3.419576e+04</td>\n",
       "      <td>73.300198</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.059106</td>\n",
       "      <td>0.032355</td>\n",
       "      <td>0.405852</td>\n",
       "      <td>0.077665</td>\n",
       "      <td>1.388918</td>\n",
       "      <td>0.573406</td>\n",
       "      <td>1.914201</td>\n",
       "      <td>6.674354</td>\n",
       "      <td>27.572386</td>\n",
       "      <td>0.104726</td>\n",
       "      <td>0.737701</td>\n",
       "      <td>2.365624</td>\n",
       "      <td>3.441229</td>\n",
       "      <td>0.199964</td>\n",
       "      <td>0.067412</td>\n",
       "      <td>0.136151</td>\n",
       "      <td>0.221930</td>\n",
       "      <td>0.029525</td>\n",
       "      <td>0.102339</td>\n",
       "      <td>0.091104</td>\n",
       "      <td>0.030638</td>\n",
       "      <td>0.012432</td>\n",
       "      <td>0.003352</td>\n",
       "      <td>0.005265</td>\n",
       "      <td>0.006839</td>\n",
       "      <td>0.002607</td>\n",
       "      <td>0.005662</td>\n",
       "      <td>0.009771</td>\n",
       "      <td>0.008517</td>\n",
       "      <td>0.002396</td>\n",
       "      <td>0.001011</td>\n",
       "      <td>35.077691</td>\n",
       "      <td>13.062043</td>\n",
       "      <td>1.399857</td>\n",
       "      <td>5.056648</td>\n",
       "      <td>2.452354</td>\n",
       "      <td>1.81221</td>\n",
       "      <td>3.034308</td>\n",
       "      <td>1.575873</td>\n",
       "      <td>3.619644</td>\n",
       "      <td>1.49582</td>\n",
       "      <td>0.788626</td>\n",
       "      <td>0.135583</td>\n",
       "      <td>1.003495</td>\n",
       "      <td>2.366116</td>\n",
       "      <td>0.259408</td>\n",
       "      <td>0.307151</td>\n",
       "      <td>0.121537</td>\n",
       "      <td>12.831905</td>\n",
       "      <td>3.559494</td>\n",
       "      <td>2.249557</td>\n",
       "      <td>21.438658</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>38739.77005</td>\n",
       "      <td>0.499816</td>\n",
       "      <td>4.374971e+05</td>\n",
       "      <td>6997.695671</td>\n",
       "      <td>6.878021e+04</td>\n",
       "      <td>7.510120e+04</td>\n",
       "      <td>1083.274277</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.167819</td>\n",
       "      <td>0.176942</td>\n",
       "      <td>0.239223</td>\n",
       "      <td>0.026184</td>\n",
       "      <td>1.471604</td>\n",
       "      <td>28.436726</td>\n",
       "      <td>122.041183</td>\n",
       "      <td>406.542579</td>\n",
       "      <td>1831.425703</td>\n",
       "      <td>0.458687</td>\n",
       "      <td>0.439886</td>\n",
       "      <td>1.351617</td>\n",
       "      <td>2.479373</td>\n",
       "      <td>0.276376</td>\n",
       "      <td>0.165502</td>\n",
       "      <td>0.242561</td>\n",
       "      <td>0.298133</td>\n",
       "      <td>0.106880</td>\n",
       "      <td>0.206059</td>\n",
       "      <td>0.190366</td>\n",
       "      <td>0.116949</td>\n",
       "      <td>0.070884</td>\n",
       "      <td>0.037525</td>\n",
       "      <td>0.048690</td>\n",
       "      <td>0.053513</td>\n",
       "      <td>0.032400</td>\n",
       "      <td>0.046830</td>\n",
       "      <td>0.070224</td>\n",
       "      <td>0.062580</td>\n",
       "      <td>0.030757</td>\n",
       "      <td>0.019590</td>\n",
       "      <td>13.604442</td>\n",
       "      <td>3.044782</td>\n",
       "      <td>2.795407</td>\n",
       "      <td>0.825737</td>\n",
       "      <td>2.049247</td>\n",
       "      <td>1.73699</td>\n",
       "      <td>2.012125</td>\n",
       "      <td>1.546382</td>\n",
       "      <td>2.195625</td>\n",
       "      <td>1.63947</td>\n",
       "      <td>0.961242</td>\n",
       "      <td>0.379235</td>\n",
       "      <td>1.086844</td>\n",
       "      <td>2.140459</td>\n",
       "      <td>0.903957</td>\n",
       "      <td>0.774367</td>\n",
       "      <td>0.453865</td>\n",
       "      <td>15.557524</td>\n",
       "      <td>6.674458</td>\n",
       "      <td>2.912136</td>\n",
       "      <td>9.625147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>33549.25000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.000000e+01</td>\n",
       "      <td>168.000000</td>\n",
       "      <td>1.356000e+03</td>\n",
       "      <td>3.046000e+03</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.030000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.223684</td>\n",
       "      <td>0.061814</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4.571429</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>14.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>67098.50000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.540000e+02</td>\n",
       "      <td>567.000000</td>\n",
       "      <td>8.377000e+03</td>\n",
       "      <td>1.101900e+04</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.030000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.386691</td>\n",
       "      <td>0.079436</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>37.000000</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4.955556</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>21.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>100647.75000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.573000e+03</td>\n",
       "      <td>1726.000000</td>\n",
       "      <td>3.352650e+04</td>\n",
       "      <td>3.357375e+04</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.030000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.525020</td>\n",
       "      <td>0.095308</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>46.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>5.409091</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>3.00000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>2.00000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>28.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>134197.00000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.306019e+08</td>\n",
       "      <td>586901.000000</td>\n",
       "      <td>1.765080e+06</td>\n",
       "      <td>2.958918e+06</td>\n",
       "      <td>222193.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.208606</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>5913.000000</td>\n",
       "      <td>42068.000000</td>\n",
       "      <td>126062.000000</td>\n",
       "      <td>460320.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>110.000000</td>\n",
       "      <td>145.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>88.000000</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>15.00000</td>\n",
       "      <td>17.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>14.00000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>66.000000</td>\n",
       "      <td>43.000000</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>250.000000</td>\n",
       "      <td>138.000000</td>\n",
       "      <td>47.000000</td>\n",
       "      <td>164.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Unnamed: 0  BinaryNumTarget  followers_count  friends_count  \\\n",
       "count  134198.00000    134198.000000     1.341980e+05  134198.000000   \n",
       "mean    67098.50000         0.513644     1.129308e+04    1893.454455   \n",
       "std     38739.77005         0.499816     4.374971e+05    6997.695671   \n",
       "min         0.00000         0.000000     0.000000e+00       0.000000   \n",
       "25%     33549.25000         0.000000     7.000000e+01     168.000000   \n",
       "50%     67098.50000         1.000000     3.540000e+02     567.000000   \n",
       "75%    100647.75000         1.000000     1.573000e+03    1726.000000   \n",
       "max    134197.00000         1.000000     1.306019e+08  586901.000000   \n",
       "\n",
       "       favourites_count  statuses_count   listed_count  following  \\\n",
       "count      1.341980e+05    1.341980e+05  134198.000000   134198.0   \n",
       "mean       3.298123e+04    3.419576e+04      73.300198        0.0   \n",
       "std        6.878021e+04    7.510120e+04    1083.274277        0.0   \n",
       "min        0.000000e+00    1.000000e+00       0.000000        0.0   \n",
       "25%        1.356000e+03    3.046000e+03       0.000000        0.0   \n",
       "50%        8.377000e+03    1.101900e+04       2.000000        0.0   \n",
       "75%        3.352650e+04    3.357375e+04      11.000000        0.0   \n",
       "max        1.765080e+06    2.958918e+06  222193.000000        0.0   \n",
       "\n",
       "            BotScore  BotScoreBinary           cred  normalize_influence  \\\n",
       "count  134198.000000   134198.000000  134198.000000        134198.000000   \n",
       "mean        0.059106        0.032355       0.405852             0.077665   \n",
       "std         0.167819        0.176942       0.239223             0.026184   \n",
       "min         0.000000        0.000000       0.000000             0.000000   \n",
       "25%         0.030000        0.000000       0.223684             0.061814   \n",
       "50%         0.030000        0.000000       0.386691             0.079436   \n",
       "75%         0.030000        0.000000       0.525020             0.095308   \n",
       "max         1.000000        1.000000       1.000000             0.208606   \n",
       "\n",
       "            mentions         quotes        replies       retweets  \\\n",
       "count  134198.000000  134198.000000  134198.000000  134198.000000   \n",
       "mean        1.388918       0.573406       1.914201       6.674354   \n",
       "std         1.471604      28.436726     122.041183     406.542579   \n",
       "min         0.000000       0.000000       0.000000       0.000000   \n",
       "25%         0.000000       0.000000       0.000000       0.000000   \n",
       "50%         1.000000       0.000000       0.000000       0.000000   \n",
       "75%         2.000000       0.000000       1.000000       0.000000   \n",
       "max        12.000000    5913.000000   42068.000000  126062.000000   \n",
       "\n",
       "          favourites       hashtags           URLs   unique_count  \\\n",
       "count  134198.000000  134198.000000  134198.000000  134198.000000   \n",
       "mean       27.572386       0.104726       0.737701       2.365624   \n",
       "std      1831.425703       0.458687       0.439886       1.351617   \n",
       "min         0.000000       0.000000       0.000000       0.000000   \n",
       "25%         0.000000       0.000000       0.000000       1.000000   \n",
       "50%         0.000000       0.000000       1.000000       2.000000   \n",
       "75%         1.000000       0.000000       1.000000       3.000000   \n",
       "max    460320.000000      12.000000       1.000000       9.000000   \n",
       "\n",
       "         total_count  ORG_percentage  NORP_percentage  GPE_percentage  \\\n",
       "count  134198.000000   134198.000000    134198.000000   134198.000000   \n",
       "mean        3.441229        0.199964         0.067412        0.136151   \n",
       "std         2.479373        0.276376         0.165502        0.242561   \n",
       "min         0.000000        0.000000         0.000000        0.000000   \n",
       "25%         2.000000        0.000000         0.000000        0.000000   \n",
       "50%         3.000000        0.000000         0.000000        0.000000   \n",
       "75%         5.000000        0.333333         0.000000        0.222222   \n",
       "max        32.000000        1.000000         1.000000        1.000000   \n",
       "\n",
       "       PERSON_percentage  MONEY_percentage  DATE_percentage  \\\n",
       "count      134198.000000     134198.000000    134198.000000   \n",
       "mean            0.221930          0.029525         0.102339   \n",
       "std             0.298133          0.106880         0.206059   \n",
       "min             0.000000          0.000000         0.000000   \n",
       "25%             0.000000          0.000000         0.000000   \n",
       "50%             0.000000          0.000000         0.000000   \n",
       "75%             0.333333          0.000000         0.142857   \n",
       "max             1.000000          1.000000         1.000000   \n",
       "\n",
       "       CARDINAL_percentage  PERCENT_percentage  ORDINAL_percentage  \\\n",
       "count        134198.000000       134198.000000       134198.000000   \n",
       "mean              0.091104            0.030638            0.012432   \n",
       "std               0.190366            0.116949            0.070884   \n",
       "min               0.000000            0.000000            0.000000   \n",
       "25%               0.000000            0.000000            0.000000   \n",
       "50%               0.000000            0.000000            0.000000   \n",
       "75%               0.090909            0.000000            0.000000   \n",
       "max               1.000000            1.000000            1.000000   \n",
       "\n",
       "       FAC_percentage  LAW_percentage  PRODUCT_percentage  EVENT_percentage  \\\n",
       "count   134198.000000   134198.000000       134198.000000     134198.000000   \n",
       "mean         0.003352        0.005265            0.006839          0.002607   \n",
       "std          0.037525        0.048690            0.053513          0.032400   \n",
       "min          0.000000        0.000000            0.000000          0.000000   \n",
       "25%          0.000000        0.000000            0.000000          0.000000   \n",
       "50%          0.000000        0.000000            0.000000          0.000000   \n",
       "75%          0.000000        0.000000            0.000000          0.000000   \n",
       "max          1.000000        1.000000            1.000000          1.000000   \n",
       "\n",
       "       TIME_percentage  LOC_percentage  WORK_OF_ART_percentage  \\\n",
       "count    134198.000000   134198.000000           134198.000000   \n",
       "mean          0.005662        0.009771                0.008517   \n",
       "std           0.046830        0.070224                0.062580   \n",
       "min           0.000000        0.000000                0.000000   \n",
       "25%           0.000000        0.000000                0.000000   \n",
       "50%           0.000000        0.000000                0.000000   \n",
       "75%           0.000000        0.000000                0.000000   \n",
       "max           1.000000        1.000000                1.000000   \n",
       "\n",
       "       QUANTITY_percentage  LANGUAGE_percentage     Word count  \\\n",
       "count        134198.000000        134198.000000  134198.000000   \n",
       "mean              0.002396             0.001011      35.077691   \n",
       "std               0.030757             0.019590      13.604442   \n",
       "min               0.000000             0.000000       0.000000   \n",
       "25%               0.000000             0.000000      23.000000   \n",
       "50%               0.000000             0.000000      37.000000   \n",
       "75%               0.000000             0.000000      46.000000   \n",
       "max               1.000000             1.000000     110.000000   \n",
       "\n",
       "       Max word length  Min word length  Average word length  present_verbs  \\\n",
       "count    134198.000000    134198.000000        134198.000000  134198.000000   \n",
       "mean         13.062043         1.399857             5.056648       2.452354   \n",
       "std           3.044782         2.795407             0.825737       2.049247   \n",
       "min           0.000000         1.000000            -1.000000       0.000000   \n",
       "25%          11.000000         1.000000             4.571429       1.000000   \n",
       "50%          13.000000         1.000000             4.955556       2.000000   \n",
       "75%          15.000000         2.000000             5.409091       4.000000   \n",
       "max         145.000000      1000.000000            88.000000      16.000000   \n",
       "\n",
       "         past_verbs     adjectives        adverbs    adpositions  \\\n",
       "count  134198.00000  134198.000000  134198.000000  134198.000000   \n",
       "mean        1.81221       3.034308       1.575873       3.619644   \n",
       "std         1.73699       2.012125       1.546382       2.195625   \n",
       "min         0.00000       0.000000       0.000000       0.000000   \n",
       "25%         0.00000       2.000000       0.000000       2.000000   \n",
       "50%         1.00000       3.000000       1.000000       3.000000   \n",
       "75%         3.00000       4.000000       2.000000       5.000000   \n",
       "max        15.00000      17.000000      12.000000      14.000000   \n",
       "\n",
       "           pronouns            TOs    determiners   conjunctions  \\\n",
       "count  134198.00000  134198.000000  134198.000000  134198.000000   \n",
       "mean        1.49582       0.788626       0.135583       1.003495   \n",
       "std         1.63947       0.961242       0.379235       1.086844   \n",
       "min         0.00000       0.000000       0.000000       0.000000   \n",
       "25%         0.00000       0.000000       0.000000       0.000000   \n",
       "50%         1.00000       1.000000       0.000000       1.000000   \n",
       "75%         2.00000       1.000000       0.000000       2.000000   \n",
       "max        14.00000       8.000000       5.000000      13.000000   \n",
       "\n",
       "                dots    exclamation      questions      ampersand  \\\n",
       "count  134198.000000  134198.000000  134198.000000  134198.000000   \n",
       "mean        2.366116       0.259408       0.307151       0.121537   \n",
       "std         2.140459       0.903957       0.774367       0.453865   \n",
       "min         0.000000       0.000000       0.000000       0.000000   \n",
       "25%         1.000000       0.000000       0.000000       0.000000   \n",
       "50%         2.000000       0.000000       0.000000       0.000000   \n",
       "75%         3.000000       0.000000       0.000000       0.000000   \n",
       "max        50.000000      66.000000      43.000000      13.000000   \n",
       "\n",
       "            capitals         digits  long_word_freq  short_word_freq  \n",
       "count  134198.000000  134198.000000   134198.000000    134198.000000  \n",
       "mean       12.831905       3.559494        2.249557        21.438658  \n",
       "std        15.557524       6.674458        2.912136         9.625147  \n",
       "min         0.000000       0.000000        0.000000         0.000000  \n",
       "25%         6.000000       0.000000        1.000000        14.000000  \n",
       "50%        10.000000       2.000000        2.000000        21.000000  \n",
       "75%        15.000000       4.000000        3.000000        28.000000  \n",
       "max       250.000000     138.000000       47.000000       164.000000  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "afbc1a33-8884-4c16-b04a-59ca2cffa6ab",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "convert_to_32 = ['friends_count', 'favourites_count', 'statuses_count', 'listed_count', 'following', 'replies', 'retweets', 'favourites']\n",
    "convert_to_16 = ['mentions', 'quotes',  'hashtags', 'URLs', 'unique_count', 'total_count', 'Word count', 'Max word length', 'Min word length', 'present_verbs', 'past_verbs', 'adjectives', 'adverbs', 'adpositions', 'pronouns', 'TOs', 'determiners', 'conjunctions', 'dots', 'exclamation', 'questions', 'ampersand', 'capitals', 'digits', 'short_word_freq', 'long_word_freq']\n",
    "convert_to_8 = ['BotScoreBinary', 'BinaryNumTarget']\n",
    "\n",
    "df[convert_to_32] = df[convert_to_32].astype('int32')\n",
    "df[convert_to_16] = df[convert_to_16].astype('int16')\n",
    "df[convert_to_8] = df[convert_to_8].astype('int8')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2efcaf6d-3bee-49f6-9b1a-f3bc48e232e4",
   "metadata": {},
   "source": [
    "df.info() shows that size went down from 66Mb to 40Mb. \n",
    "\n",
    "Now we'll do the same for floats. For floats it's float32 for 8 digits, float64 is for 16 digits. judging by the info we hardly need a very high precision. So float32 will do for all."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c047c856-723b-40fd-aed4-78f07ec5358b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "convert_to_float32 = ['BotScore', 'cred', 'normalize_influence', 'Average word length', 'ORG_percentage', 'NORP_percentage', 'GPE_percentage', 'MONEY_percentage', 'DATE_percentage', 'CARDINAL_percentage', 'ORDINAL_percentage', 'FAC_percentage', 'LAW_percentage', 'PRODUCT_percentage', 'EVENT_percentage', 'WORK_OF_ART_percentage', 'QUANTITY_percentage', 'LOC_percentage', 'PERCENT_percentage', 'LANGUAGE_percentage', 'TIME_percentage', 'PERSON_percentage']\n",
    "\n",
    "df[convert_to_float32] = df[convert_to_float32].astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "bc60ff5c-8dd5-47f1-a6a8-22aeb36f3ff6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 134198 entries, 0 to 134197\n",
      "Data columns (total 64 columns):\n",
      " #   Column                  Non-Null Count   Dtype  \n",
      "---  ------                  --------------   -----  \n",
      " 0   Unnamed: 0              134198 non-null  int64  \n",
      " 1   majority_target         134198 non-null  bool   \n",
      " 2   statement               134198 non-null  object \n",
      " 3   BinaryNumTarget         134198 non-null  int8   \n",
      " 4   tweet                   134198 non-null  object \n",
      " 5   followers_count         134198 non-null  float64\n",
      " 6   friends_count           134198 non-null  int32  \n",
      " 7   favourites_count        134198 non-null  int32  \n",
      " 8   statuses_count          134198 non-null  int32  \n",
      " 9   listed_count            134198 non-null  int32  \n",
      " 10  following               134198 non-null  int32  \n",
      " 11  embeddings              134198 non-null  object \n",
      " 12  BotScore                134198 non-null  float32\n",
      " 13  BotScoreBinary          134198 non-null  int8   \n",
      " 14  cred                    134198 non-null  float32\n",
      " 15  normalize_influence     134198 non-null  float32\n",
      " 16  mentions                134198 non-null  int16  \n",
      " 17  quotes                  134198 non-null  int16  \n",
      " 18  replies                 134198 non-null  int32  \n",
      " 19  retweets                134198 non-null  int32  \n",
      " 20  favourites              134198 non-null  int32  \n",
      " 21  hashtags                134198 non-null  int16  \n",
      " 22  URLs                    134198 non-null  int16  \n",
      " 23  unique_count            134198 non-null  int16  \n",
      " 24  total_count             134198 non-null  int16  \n",
      " 25  ORG_percentage          134198 non-null  float32\n",
      " 26  NORP_percentage         134198 non-null  float32\n",
      " 27  GPE_percentage          134198 non-null  float32\n",
      " 28  PERSON_percentage       134198 non-null  float32\n",
      " 29  MONEY_percentage        134198 non-null  float32\n",
      " 30  DATE_percentage         134198 non-null  float32\n",
      " 31  CARDINAL_percentage     134198 non-null  float32\n",
      " 32  PERCENT_percentage      134198 non-null  float32\n",
      " 33  ORDINAL_percentage      134198 non-null  float32\n",
      " 34  FAC_percentage          134198 non-null  float32\n",
      " 35  LAW_percentage          134198 non-null  float32\n",
      " 36  PRODUCT_percentage      134198 non-null  float32\n",
      " 37  EVENT_percentage        134198 non-null  float32\n",
      " 38  TIME_percentage         134198 non-null  float32\n",
      " 39  LOC_percentage          134198 non-null  float32\n",
      " 40  WORK_OF_ART_percentage  134198 non-null  float32\n",
      " 41  QUANTITY_percentage     134198 non-null  float32\n",
      " 42  LANGUAGE_percentage     134198 non-null  float32\n",
      " 43  Word count              134198 non-null  int16  \n",
      " 44  Max word length         134198 non-null  int16  \n",
      " 45  Min word length         134198 non-null  int16  \n",
      " 46  Average word length     134198 non-null  float32\n",
      " 47  present_verbs           134198 non-null  int16  \n",
      " 48  past_verbs              134198 non-null  int16  \n",
      " 49  adjectives              134198 non-null  int16  \n",
      " 50  adverbs                 134198 non-null  int16  \n",
      " 51  adpositions             134198 non-null  int16  \n",
      " 52  pronouns                134198 non-null  int16  \n",
      " 53  TOs                     134198 non-null  int16  \n",
      " 54  determiners             134198 non-null  int16  \n",
      " 55  conjunctions            134198 non-null  int16  \n",
      " 56  dots                    134198 non-null  int16  \n",
      " 57  exclamation             134198 non-null  int16  \n",
      " 58  questions               134198 non-null  int16  \n",
      " 59  ampersand               134198 non-null  int16  \n",
      " 60  capitals                134198 non-null  int16  \n",
      " 61  digits                  134198 non-null  int16  \n",
      " 62  long_word_freq          134198 non-null  int16  \n",
      " 63  short_word_freq         134198 non-null  int16  \n",
      "dtypes: bool(1), float32(22), float64(1), int16(26), int32(8), int64(1), int8(2), object(3)\n",
      "memory usage: 27.5+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f336a4da-64cc-4d2f-b735-d2ce35f51c72",
   "metadata": {},
   "source": [
    "Ok, we reduced the size to 27.5Mb. With dropping the unnecessary variables th size will go even lower."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dab8659-30cb-4381-8fc9-3ddc96382ec8",
   "metadata": {},
   "source": [
    "Now we're gonna drop some unnecessary columns: Unnamed 0, following, embeddings (not sure what's that for considering how it looks), majority_atrget (we're having binary representation)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7c4633dc-bccc-4f8e-a1d5-336d4da57627",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df.drop(columns=['Unnamed: 0', 'majority_target', 'following', 'embeddings'], inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "41ee90b7-363a-4966-9b91-46887d9f986b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(134198, 60)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51affa1b-1a16-46c5-b347-50a9f2ea67f5",
   "metadata": {},
   "source": [
    "# Feature recalculations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "067d64be-def4-4caa-96a3-3c7e9e9387af",
   "metadata": {},
   "source": [
    "First we need to set the existing values to 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e78f1907-5b7f-493b-bfd9-18bf38877e5b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data = df[:10] # just for case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7671a7d8-dfe1-4602-9bd2-0c1ea4a7065b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data[['total_count', 'exclamation', 'questions', 'ampersand', 'digits', 'dots', 'capitals', 'URLs', 'Max word length', 'Min word length', 'Average word length']] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a5935078-0b38-4e25-b724-c49b1620a0e2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Calculate total_count\n",
    "data['calculated_total_count'] = data['tweet'].apply(lambda x: len(str(x).split()))\n",
    "incorrect_counts = data[data['calculated_total_count'] != data['total_count']]\n",
    "data['total_count'] = data['calculated_total_count']\n",
    "data = data.drop(columns=['calculated_total_count'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "28dcba1a-f9ea-4ac1-8d65-e31d94c8eafb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# exclamation signs\n",
    "data['exclamation_count'] = data['tweet'].str.count('!')\n",
    "data['exclamation'] = data['exclamation'] + data['exclamation_count']\n",
    "data.drop(columns=['exclamation_count'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4a6308f7-859b-48cb-a008-449d7fa41bca",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# question signs\n",
    "data['quest_count'] = data['tweet'].str.count('\\?')\n",
    "data['questions'] = data['questions'] + data['quest_count']\n",
    "data.drop(columns=['quest_count'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4f9b7d0b-8774-480c-9ab9-de024966e2ed",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ampersands\n",
    "data['feature_count'] = data['tweet'].str.count('&')\n",
    "data['ampersand'] = data['ampersand'] + data['feature_count']\n",
    "data.drop(columns=['feature_count'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "216cd230-7c26-4d68-81ce-d0d6e5f2f9fc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# digits\n",
    "data['digit_count'] = data['tweet'].str.findall(r'\\b\\d+\\.?\\d*\\b').apply(len)\n",
    "data['digits'] = data['digit_count']\n",
    "data.drop(columns=['digit_count'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "0345972f-0a6c-4762-bf72-f643215a44c9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# dots\n",
    "data['feature_count'] = data['tweet'].str.count('\\.')\n",
    "data['dots'] = data['dots'] + data['feature_count']\n",
    "data.drop(columns=['feature_count'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e2bcc530-430a-45f8-988a-daf3ba605f5d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# capitals\n",
    "data['feature_count'] = data['tweet'].str.findall(r'\\b[A-Z][a-z]*\\b').apply(len)\n",
    "data['capitals'] = data['capitals'] + data['feature_count']\n",
    "data.drop(columns=['feature_count'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "784f538c-3462-47f7-84f3-8862205aee8a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# URLs\n",
    "import re\n",
    "\n",
    "def recount_urls(text):\n",
    "    # Improved regex pattern to match various URL formats\n",
    "    pattern = r'\\b(?:http://|https://)?(?:www\\.)?[\\w.-]+\\.[a-z]{2,6}\\b(?:/[\\w.-]*)*'\n",
    "    return len(re.findall(pattern, text, re.IGNORECASE))\n",
    "\n",
    "data['URLs'] = data['tweet'].apply(recount_urls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "1e60925b-ef1b-4a60-8bd0-d33c3c13d44c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Word length features\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "7b673e3b-631c-43d5-a056-564c08f8befe",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# function to find word lengths, we'll use for the next features\n",
    "def word_lengths(text):\n",
    "    words = text.split()\n",
    "    lengths = [len(word.strip(string.punctuation)) for word in words]\n",
    "    return lengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "d9679419-0c3b-4859-a7bd-78da9254d5fa",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Max word length\n",
    "data['Max word length'] = data['tweet'].apply(lambda x: max(word_lengths(x)) if word_lengths(x) else 0)\n",
    "\n",
    "# min word lenggth\n",
    "data['Min word length'] = data['tweet'].apply(lambda x: min(word_lengths(x)) if word_lengths(x) else 0)\n",
    "\n",
    "# Avg. word length\n",
    "data['Average word length'] = data['tweet'].apply(lambda x: sum(word_lengths(x)) / len(word_lengths(x)) if word_lengths(x) else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "5c7c012e-7e44-414e-ba23-d6133b0c781b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# hashtags\n",
    "data['hashtags'] = 0\n",
    "data['feature_count'] = data['tweet'].str.count('#')\n",
    "data['hashtags'] = data['hashtags'] + data['feature_count']\n",
    "data.drop(columns=['feature_count'], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40bf7ef8-f913-4b01-a4ce-39c64734d18d",
   "metadata": {},
   "source": [
    "## spacy lexical recalculations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9837117c-c6d2-4db3-861f-9ac4c913fe49",
   "metadata": {},
   "source": [
    "Now to the lexical features.\n",
    "\n",
    "That's more complex. Took me a while to get it how it words and deal with importing the lib and pipelines. There was not problem with the smaller pipeline, which works faster, but it took some time to setup the larger and more 'accurate' pipeline en_core_web_trf."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "bd444230-1643-4132-b211-2ecfafea7709",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23dd77a6-4c2f-4933-a495-1f09f381dd24",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d84f9a0e-69fb-4972-8990-add860e5d52e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# I don't want to do that 'inplace', so i'll make additional features, then drop the old features.\n",
    "\n",
    "def count_pos(text):\n",
    "    doc = nlp(text)\n",
    "    pos_counts = {\n",
    "        'present_verbs_g': 0,\n",
    "        'past_verbs_g': 0,\n",
    "        'adjectives_g': 0,\n",
    "        'adverbs_g': 0,\n",
    "        'adpositions_g': 0,\n",
    "        'pronouns_g': 0,\n",
    "        'TOs_g': 0,\n",
    "        'determiners_g': 0,\n",
    "        'conjunctions_g': 0\n",
    "    }\n",
    "    for token in doc:\n",
    "        if token.pos_ == 'VERB':\n",
    "            if token.tag_ in ['VB', 'VBP', 'VBZ']:\n",
    "                pos_counts['present_verbs_g'] += 1\n",
    "            elif token.tag_ in ['VBD', 'VBN']:\n",
    "                pos_counts['past_verbs_g'] += 1\n",
    "        elif token.pos_ == 'ADJ':\n",
    "            pos_counts['adjectives_g'] += 1\n",
    "        elif token.pos_ == 'ADV':\n",
    "            pos_counts['adverbs_g'] += 1\n",
    "        elif token.pos_ == 'ADP':\n",
    "            pos_counts['adpositions_g'] += 1\n",
    "        elif token.pos_ == 'PRON':\n",
    "            pos_counts['pronouns_g'] += 1\n",
    "        elif token.text == 'to':\n",
    "            pos_counts['TOs_g'] += 1\n",
    "        elif token.pos_ == 'DET':\n",
    "            pos_counts['determiners_g'] += 1\n",
    "        elif token.pos_ == 'CCONJ' or token.pos_ == 'SCONJ':\n",
    "            pos_counts['conjunctions_g'] += 1\n",
    "    return pd.Series(pos_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e36d9de2-7177-4d51-befb-03d13260033e",
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_counts_df = data['tweet'].apply(count_pos)\n",
    "df = data.join(pos_counts_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f26f115-b212-4be6-947f-e1de540a668c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dropppinf old and renaming\n",
    "data.drop(columns=['present_verbs', 'past_verbs', 'adjectives', 'adverbs', 'adpositions', 'pronouns', 'TOs', 'determiners', 'conjunctions'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c511f96-7eee-418d-a1a0-e97e28a3241b",
   "metadata": {},
   "outputs": [],
   "source": [
    "ren_columns = {'present_verbs_g' : 'present_verbs', \n",
    "               'past_verbs_g' : 'past_verbs', \n",
    "               'adjectives_g': 'adjectives', \n",
    "               'adverbs_g' : 'adverbs', \n",
    "               'adpositions_g' : 'adpositions', \n",
    "               'pronouns_g' : 'pronouns', \n",
    "               'TOs_g' : 'TOs', \n",
    "               'determiners_g' : 'determiners', \n",
    "               'conjunctions_g' : 'conjunctions' \n",
    "              }\n",
    "data.rename(columns=ren_columns, inplace=True)\n",
    "data.drop(columns=['present_verbs_g','past_verbs_g','adjectives_g','adverbs_g','adpositions_g','pronouns_g','TOs_g','determiners_g','conjunctions_g'], inplace=True)\n",
    "# ok that could have been done in a more efficient pythonic way..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fe4482a-efa7-48ec-9e67-443c4decbcc7",
   "metadata": {},
   "source": [
    "#### Now about short/long"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "113c3de3-ba86-4e8b-b6f9-e23b3f83b263",
   "metadata": {},
   "source": [
    "I tried to find out what the researchers meant by the short and long words. 5 characters -- is it short or long? \n",
    "\n",
    "So I decided to recalculate that too and did a tiny research.\n",
    "\n",
    "In English a short word is considered to be a word of 3 letters. Then go middle words. And from 7 and up -- the long words. We don't want (for now?) to implement a new feature -- \"middle word\". So we'll be considering everything starting from 7 as long, axnd below that threshold as short words. 7 is long.\n",
    "\n",
    "_so say we all_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "cbeed0ef-3e7f-4918-b7bf-2b80618cb753",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Blunders\n",
      "Inflation\n",
      "mismanagement\n",
      "Abandoning\n",
      "Americans\n",
      "Afghanistan\n",
      "Taliban\n",
      "Breaking\n",
      "through\n",
      "Reconciliation\n",
      "Eviction\n",
      "Moratorium\n"
     ]
    }
   ],
   "source": [
    "# tiny test\n",
    "text = '@POTUS Biden Blunders - 6 Month Update\\n\\nInflation, Delta mismanagement, COVID for kids, Abandoning Americans in Afghanistan, Arming the Taliban, S. Border crisis, Breaking job growth, Abuse of power (Many Exec Orders, $3.5T through Reconciliation, Eviction Moratorium)...what did I miss?'\n",
    "w = re.findall(r'\\b\\w+\\b', text)\n",
    "# w = text.split()\n",
    "for word in w:\n",
    "    if word.isalpha() and len(word) >6:\n",
    "        print(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "8ab3aea4-a3c0-4af4-80b5-c7b9b830de18",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "threshold = 7\n",
    "\n",
    "def count_word_types(text):\n",
    "    words = re.findall(r'\\b\\w+\\b', text)\n",
    "    short_words = sum(1 for word in words if word.isalpha() and len(word) < threshold)\n",
    "    long_words = sum(1 for word in words if word.isalpha() and len(word) >= threshold)\n",
    "    return pd.Series({\n",
    "        'short_word_freq': short_words,\n",
    "        'long_word_freq': long_words\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "03e4512e-051f-4d4b-a6f4-9dcfb8564fb3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# drop existing columns\n",
    "data.drop(columns=['long_word_freq','short_word_freq'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "c63f3c98-cb2c-4ca5-a81a-d0909234c2de",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "word_counts_df = data['tweet'].apply(count_word_types)\n",
    "data = data.join(word_counts_df)\n",
    "\n",
    "# now at least we know what stands behind short and long"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07eedc5c-0d81-495d-8cc2-a177489b085c",
   "metadata": {},
   "source": [
    "### spacy tags recalculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5af5cf10-07af-4d03-b099-03caa73ef3e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# same as before, i want to keep the existing columns and add the new ones to compare the results\n",
    "def calculate_entity_percentages(text):\n",
    "    doc = nlp(text)\n",
    "    total_tokens = len(doc)\n",
    "    \n",
    "    entity_counts = {\n",
    "            'ORG_percent': 0,\n",
    "            'GPE_percent': 0,\n",
    "            'MONEY_percent': 0,\n",
    "            'EVENT_percent': 0,\n",
    "            'PRODUCT_percent': 0,\n",
    "            'NORP_percent': 0,\n",
    "            'WORK_OF_ART_percent': 0,\n",
    "            'LAW_percent': 0,\n",
    "            'FAC_percent': 0,\n",
    "            'CARDINAL_percent': 0,\n",
    "            'QUANTITY_percent': 0,\n",
    "            'LANGUAGE_percent': 0,\n",
    "            'DATE_percent': 0,\n",
    "            'LOC_percent': 0,\n",
    "            'ORDINAL_percent': 0,\n",
    "            'PERCENT_percent': 0,\n",
    "            'PERSON_percent': 0,\n",
    "            'TIME_percent': 0\n",
    "    }\n",
    "    \n",
    "    for ent in doc.ents:\n",
    "        if ent.label_ == 'ORG':\n",
    "            entity_counts['ORG_percent'] += 1\n",
    "        elif ent.label_ == 'FAC':\n",
    "            entity_counts['FAC_percent'] += 1\n",
    "        elif ent.label_ == 'NORP':\n",
    "            entity_counts['NORP_percent'] += 1\n",
    "        elif ent.label_ == 'GPE':\n",
    "            entity_counts['GPE_percent'] += 1\n",
    "        elif ent.label_ == 'MONEY':\n",
    "            entity_counts['MONEY_percent'] += 1\n",
    "        elif ent.label_ == 'DATE':\n",
    "            entity_counts['DATE_percent'] += 1\n",
    "        elif ent.label_ == 'CARDINAL':\n",
    "            entity_counts['CARDINAL_percent'] += 1\n",
    "        elif ent.label_ == 'LAW':\n",
    "            entity_counts['LAW_percent'] += 1\n",
    "        elif ent.label_ == 'PRODUCT':\n",
    "            entity_counts['PRODUCT_percent'] += 1\n",
    "        elif ent.label_ == 'EVENT':\n",
    "            entity_counts['EVENT_percent'] += 1\n",
    "        elif ent.label_ == 'WORK_OF_ART':\n",
    "            entity_counts['WORK_OF_ART_percent'] += 1\n",
    "        elif ent.label_ == 'QUANTITY':\n",
    "            entity_counts['QUANTITY_percent'] += 1\n",
    "        elif ent.label_ == 'LANGUAGE':\n",
    "            entity_counts['LANGUAGE_percent'] += 1,\n",
    "        elif ent.label_ == 'LOC':\n",
    "            entity_counts['LOC_percent'] += 1,\n",
    "        elif ent.label_ == 'ORDINAL':\n",
    "            entity_counts['ORDINAL_percent'] += 1,\n",
    "        elif ent.label_ == 'PERCENT':\n",
    "            entity_counts['PERCENT_percent'] += 1,\n",
    "        elif ent.label_ == 'PERSON':\n",
    "            entity_counts['PERSON_percent'] += 1,\n",
    "        elif ent.label_ == 'TIME':\n",
    "            entity_counts['TIME_percent'] += 1\n",
    "    \n",
    "    for key in entity_counts.keys():\n",
    "        entity_counts[key] = (entity_counts[key] / total_tokens) * 100 if total_tokens > 0 else 0\n",
    "    \n",
    "    return pd.Series(entity_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5acc8ce-e1df-497a-97e1-2e6899d58534",
   "metadata": {},
   "outputs": [],
   "source": [
    "# that took a while to process. Like 8-9 hours.\n",
    "\n",
    "entity_percentages_df = data['tweet'].apply(calculate_entity_percentages)\n",
    "data = data.join(entity_percentages_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0626d2a8-504b-4a80-8972-56c52bdbb7c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# now we can drop the old and rename the new columns\n",
    "data.drop(columns=[\n",
    "                    'ORG_percentage', \n",
    "                    'NORP_percentage', \n",
    "                    'GPE_percentage', \n",
    "                    'PERSON_percentage', \n",
    "                    'MONEY_percentage', \n",
    "                    'DATE_percentage', \n",
    "                    'CARDINAL_percentage', \n",
    "                    'PERCENT_percentage', \n",
    "                    'ORDINAL_percentage', \n",
    "                    'FAC_percentage', \n",
    "                    'LAW_percentage', \n",
    "                    'PRODUCT_percentage', \n",
    "                    'EVENT_percentage', \n",
    "                    'TIME_percentage', \n",
    "                    'LOC_percentage', \n",
    "                    'WORK_OF_ART_percentage', \n",
    "                    'QUANTITY_percentage', \n",
    "                    'LANGUAGE_percentage'\n",
    "                     ], inplace=True)\n",
    "\n",
    "v3_data.rename(columns={\n",
    "    'ORG_percent': 'ORG_percentage',\n",
    "    'NORP_percent': 'NORP_percentage',\n",
    "    'GPE_percent': 'GPE_percentage',\n",
    "    'PERSON_percent': 'PERSON_percentage',\n",
    "    'MONEY_percent': 'MONEY_percentage',\n",
    "    'DATE_percent': 'DATE_percentage',\n",
    "    'CARDINAL_percent': 'CARDINAL_percentage',\n",
    "    'PERCENT_percent': 'PERCENT_percentage',\n",
    "    'ORDINAL_percent': 'ORDINAL_percentage',\n",
    "    'FAC_percent': 'FAC_percentage',\n",
    "    'LAW_percent': 'LAW_percentage',\n",
    "    'PRODUCT_percent': 'PRODUCT_percentage',\n",
    "    'EVENT_percent': 'EVENT_percentage',\n",
    "    'TIME_percent': 'TIME_percentage',\n",
    "    'LOC_percent': 'LOC_percentage',\n",
    "    'WORK_OF_ART_percent': 'WORK_OF_ART_percentage',\n",
    "    'QUANTITY_percent': 'QUANTITY_percentage',\n",
    "    'LANGUAGE_percent':'LANGUAGE_percentage'\n",
    "}, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9be9ebf8-0442-44ee-97cc-6cee040ce651",
   "metadata": {},
   "source": [
    "Now after vmaking sure everything looks normal, that all features are recalculaated, that the tags make sense (if there's a person in text or date we can see that in our renewed dataset PERSON and DATE tags reflect that) we can save it as a new dataset to continue work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "eee15c2b-b420-45b8-b4f4-22f48f643555",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pd.reset_option('display.max_colwidth')\n",
    "pd.reset_option('display.max_columns')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "82dde259-1f83-44e7-b9a4-82e349ad05ae",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# We can't use .csv as pandas does not preserve the new datatypes, it uses default dtypes, so we save data to parquet\n",
    "# corrected_file_path = '../data/dataset.parquet'\n",
    "# df.to_parquet(corrected_file_path, index=False)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# corrected_file_path = '../data/Features_For_Traditional_ML_Techniques_v3.csv'\n",
    "# data.to_csv(corrected_file_path, index=False)\n",
    "\n",
    "# corrected_file_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "25bc1adf-0fe6-4d38-bf4d-a466c24a43ea",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # That plot for scaled data. Scale and see how it looks\n",
    "# plt.scatter(X_train_scaled[:,0], X_train_scaled[:,1])\n",
    "# plt.title('Linearly separable data')\n",
    "# plt.xlabel('X1')\n",
    "# plt.ylabel('X2')\n",
    "# plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7010d21b-7e41-439c-ba97-9752fa7bb20c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "141ed647-5065-4725-b184-cab57e89a432",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
